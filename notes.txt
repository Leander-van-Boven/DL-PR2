Transfer
    Architecture 1
        Optimizer high impact on output
            Too high learning rate --> quick and sloppy convergence
            Too low learning rate --> no convergence, TNR of D so low that acc of G becomes close to 1
            Sweet spot?
                Adam(1e-3, .5, .999) seems to be good for both transfer directions
                
    Architecture 2
        Seems like too few dense output weights to do any good

Notransfer:
    Architecture 1
        Weird bug again where all accuracies are 1.0 w/ gibberish pictures
        Might be because of optimizer: Too high learning rate   
            Digits work better with Adam(1e-4) (and perhaps RMSprop(1e-4))

    Architecture 2
        Can't get it to work, neither Adam nor RMSprop with different params